import os
from pathlib import Path
from typing import Dict, Set, List, Tuple
import re
from urllib.parse import urlparse
from collections import defaultdict
import argparse

def validate_domain(domain: str) -> Tuple[bool, str]:
    """
    Enhanced domain validation with detailed checking.
    
    Args:
        domain: Domain name to validate
    
    Returns:
        Tuple[bool, str]: (is_valid, error_message)
    """
    if not domain:
        return False, "Empty domain"
    
    # Remove any whitespace and convert to lowercase
    domain = domain.strip().lower()
    
    # Basic length check
    if len(domain) > 253:
        return False, "Domain too long (max 253 characters)"
    
    # Check for invalid characters
    allowed_chars = re.compile(r'^[a-z0-9\-\.]+$')
    if not allowed_chars.match(domain):
        return False, "Contains invalid characters"
    
    # Split into labels
    labels = domain.split('.')
    
    # Must have at least two labels
    if len(labels) < 2:
        return False, "Missing TLD"
    
    # Check each label
    for label in labels:
        # Length check for each label
        if not label or len(label) > 63:
            return False, "Label empty or too long (max 63 characters)"
        
        # Must not start or end with hyphen
        if label.startswith('-') or label.endswith('-'):
            return False, "Label cannot start or end with hyphen"
        
        # Check for double hyphens in non-IDNA
        if '--' in label and not label.startswith('xn--'):
            return False, "Double hyphens only allowed in IDNA labels"
    
    return True, "Valid domain"

def clean_domain(domain: str) -> Tuple[str, bool]:
    """
    Clean and normalize a domain name.
    
    Args:
        domain: Raw domain string
    
    Returns:
        Tuple[str, bool]: (cleaned_domain, is_subdomain)
    """
    # Remove any whitespace
    domain = domain.strip()
    
    # Convert to lowercase
    domain = domain.lower()
    
    # Remove any protocol prefix
    if '://' in domain:
        domain = urlparse(domain).netloc
    
    # Remove any paths or query parameters
    domain = domain.split('/')[0]
    domain = domain.split('?')[0]
    
    # Remove any ports
    domain = domain.split(':')[0]
    
    # Remove any leading/trailing dots
    domain = domain.strip('.')
    
    # Remove 'www.' prefix if it exists
    if domain.startswith('www.'):
        domain = domain[4:]
    
    # Determine if it's a subdomain (has more than 2 parts)
    parts = domain.split('.')
    is_subdomain = len(parts) > 2
    
    return domain, is_subdomain

def process_domain_files(input_dir: str = ".", output_dir: str = "cleaned") -> None:
    """
    Process domain files by separating subdomains into different files.
    """
    input_path = Path(input_dir).resolve()
    output_path = Path(output_dir).resolve()
    
    print(f"Input directory: {input_path}")
    print(f"Output directory: {output_path}")
    
    # Define all possible main and subdomain files
    main_files = [
        "SpamDomains.txt",
        "MiningDomains.txt",
        "AbuseDomains.txt",
        "PhishingDomains.txt",
        "MalwareDomainsMail.txt",
        "MalwareDomains.txt",
        "WhiteListDomainsMail.txt",
        "WhiteListDomains.txt"
    ]
    
    sub_files = [
        "SpamSubDomains.txt",
        "MiningSubDomains.txt",
        "AbuseSubDomains.txt",
        "PhishingSubDomains.txt",
        "MalwareMailSubDomains.txt",
        "MalwareSubDomains.txt",
        "WhiteListMailSubDomains.txt",
        "WhiteListSubDomains.txt"
    ]
    
    # Create mapping between main and sub files
    file_mapping = dict(zip(main_files, sub_files))
    
    # Print files we're looking for
    print("\nLooking for these files:")
    for main_file, sub_file in file_mapping.items():
        main_path = input_path / main_file
        print(f"- {main_file}: {'Found' if main_path.exists() else 'Not found'}")
        print(f"  Associated subdomain file: {sub_file}")
    
    # Create output directory if it doesn't exist
    output_path.mkdir(exist_ok=True)
    print(f"\nCreated output directory: {output_path}")
    
    invalid_domains: Dict[str, List[Tuple[str, str]]] = defaultdict(list)
    
    # Process each file
    for main_file, sub_file in file_mapping.items():
        try:
            file_path = input_path / main_file
            if not file_path.exists():
                print(f"Warning: {main_file} not found. Skipping.")
                continue

            main_domains = set()
            subdomains = set()
            
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    domain = line.strip()
                    if not domain or domain.startswith('#'):
                        continue
                    
                    cleaned_domain, is_subdomain = clean_domain(domain)
                    is_valid, error_msg = validate_domain(cleaned_domain)
                    
                    if is_valid:
                        if is_subdomain:
                            subdomains.add(cleaned_domain)
                        else:
                            main_domains.add(cleaned_domain)
                    else:
                        invalid_domains[main_file].append((domain, error_msg))
            
            # Write main domains
            if main_domains:
                output_file = output_path / f"cleaned_{main_file}"
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(sorted(main_domains)))
                print(f"Created {output_file} with {len(main_domains)} domains")
            
            # Write subdomains if any found
            if subdomains:
                output_file = output_path / f"cleaned_{sub_file}"
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(sorted(subdomains)))
                print(f"Created {output_file} with {len(subdomains)} subdomains")
            
        except Exception as e:
            print(f"Error processing {main_file}: {str(e)}")
    
    # Write invalid domains report
    if invalid_domains:
        invalid_file = output_path / "invalid_domains.txt"
        with open(invalid_file, 'w', encoding='utf-8') as f:
            f.write("Invalid Domains Report\n")
            f.write("====================\n\n")
            for file_name, domains in invalid_domains.items():
                f.write(f"\n{file_name}:\n")
                for domain, error in domains:
                    f.write(f"  - {domain}: {error}\n")
        print(f"\nWarning: Found invalid domains. See {invalid_file} for details")

if __name__ == "__main__":    
    parser = argparse.ArgumentParser(description='Process domain files and separate subdomains.')
    parser.add_argument('--input-dir', default=".", help='Directory containing domain files')
    parser.add_argument('--output-dir', default="cleaned", help='Directory for cleaned files')
    
    args = parser.parse_args()
    process_domain_files(args.input_dir, args.output_dir)